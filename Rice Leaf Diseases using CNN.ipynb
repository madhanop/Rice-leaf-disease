{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d82cac1a",
   "metadata": {},
   "source": [
    "# Detection and Classification of Rice Leaf Diseases using Convolutional Neural Networks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e901b51",
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install utils\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0e2d051e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import models, layers\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import numpy as np\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras import models\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras import optimizers\n",
    "%matplotlib inline\n",
    "from keras.utils import np_utils\n",
    "from tensorflow import keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ea156648",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 5932 files belonging to 5 classes.\n"
     ]
    }
   ],
   "source": [
    "riceleaf = tf.keras.preprocessing.image_dataset_from_directory(r\"C:\\Users\\Home\\Desktop\\Rice Leaf Disease\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "8ce73190",
   "metadata": {},
   "outputs": [],
   "source": [
    "#riceleaf = tf.keras.models.image_dataset_from_directory(r\"C:\\Users\\Home\\Desktop\\Rice Leaf Disease\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "8beec553",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 4153 images belonging to 5 classes.\n",
      "Found 1779 images belonging to 5 classes.\n"
     ]
    }
   ],
   "source": [
    "datagen = ImageDataGenerator(\n",
    "    rotation_range=30, width_shift_range=0.15,\n",
    "    height_shift_range=0.15, shear_range=0.15, \n",
    "    zoom_range=0.2,horizontal_flip=True, \n",
    "    fill_mode=\"nearest\", validation_split=0.3)\n",
    "batch_size = 32\n",
    "\n",
    "train_generator = datagen.flow_from_directory(\n",
    "    r\"C:\\Users\\Home\\Desktop\\Rice Leaf Disease\",\n",
    "    target_size=(224, 224),\n",
    "    batch_size=batch_size,\n",
    "    class_mode='categorical',\n",
    "    subset='training')\n",
    "\n",
    "val_generator = datagen.flow_from_directory(\n",
    "    r\"C:\\Users\\Home\\Desktop\\Rice Leaf Disease\",\n",
    "    target_size=(224, 224),\n",
    "    batch_size=batch_size,\n",
    "    class_mode='categorical',\n",
    "    subset='validation')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f146ef0b",
   "metadata": {},
   "source": [
    "## Modeling\n",
    "For the modeling, we used different pre-trained models. Six architectures were used:\n",
    "\n",
    "1.VGG16 base for feature extraction and 3-dense layers for classification.\n",
    "\n",
    "2.VGG16 base with only the first 3 blocks frozen and 3-dense layers.\n",
    "\n",
    "3.VGG19 base and 3-dense layers.\n",
    "\n",
    "4.XCeption base and 3-dense layers.\n",
    "\n",
    "5.ResNet base and 3-dense layers.\n",
    "\n",
    "6.5 convolutional layers and 2-dense layer."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c72fc96b",
   "metadata": {},
   "source": [
    "## VGG16"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "8f38a84f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.callbacks import ModelCheckpoint, ReduceLROnPlateau\n",
    "\n",
    "checkpoint = ModelCheckpoint('VGG16.h5', verbose=1, monitor='val_accuracy', save_best_only=True, mode='auto')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "0057e4da",
   "metadata": {},
   "outputs": [],
   "source": [
    "datagen = ImageDataGenerator(\n",
    "    rotation_range=30, width_shift_range=0.15,\n",
    "    height_shift_range=0.15, shear_range=0.15, \n",
    "    zoom_range=0.2,horizontal_flip=True, \n",
    "    fill_mode=\"nearest\")\n",
    "# datagen = ImageDataGenerator(rescale=1./255)\n",
    "\n",
    "def extract_features(trainorval, sample_count):\n",
    "    features = np.zeros(shape=(sample_count, 7, 7, 512))\n",
    "    labels = np.zeros(shape=(sample_count, 4))\n",
    "    if trainorval==\"training\":\n",
    "        generator = train_generator\n",
    "    else:\n",
    "        generator = val_generator\n",
    "    i = 0\n",
    "    for inputs_batch, labels_batch in generator:\n",
    "        features_batch = conv_base.predict(preprocess_input(inputs_batch))\n",
    "        try:\n",
    "            features[i * batch_size : (i + 1) * batch_size] = features_batch\n",
    "            labels[i * batch_size : (i + 1) * batch_size] = labels_batch\n",
    "        except ValueError:\n",
    "            break\n",
    "        i += 1\n",
    "        if i * batch_size >= sample_count:\n",
    "            break\n",
    "    return features, labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "a4126faf",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.applications.vgg16 import VGG16, preprocess_input\n",
    "\n",
    "conv_base = VGG16(weights='imagenet',\n",
    "                  include_top=False,\n",
    "                  input_shape=(224, 224, 3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "ef63ddb0",
   "metadata": {},
   "outputs": [],
   "source": [
    "conv_base.trainable = True\n",
    "for layer in conv_base.layers:\n",
    "    layer.trainable = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "a60f2aa2",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "train_features, train_labels = extract_features('training', 2319)\n",
    "validation_features, validation_labels = extract_features('validation', 991)\n",
    "\n",
    "train_features = np.reshape(train_features, (2319, 7 * 7 * 512))\n",
    "validation_features = np.reshape(validation_features, (991, 7 * 7 * 512))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "01c2b015",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = models.Sequential()\n",
    "model.add(layers.Dense(256, activation='relu', input_dim=(25088)))\n",
    "model.add(layers.Dropout(0.2))\n",
    "model.add(layers.Dense(128, activation='relu'))\n",
    "model.add(layers.Dropout(0.2))  #Removing 50% of the weights!\n",
    "model.add(layers.Dense(4, activation='softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "b210cb1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.optimizers import Adam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "03f2b30d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Home\\anaconda3\\lib\\site-packages\\tensorflow\\python\\keras\\optimizer_v2\\optimizer_v2.py:374: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "INIT_LR = 1e-1\n",
    "EPOCHS = 30\n",
    "\n",
    "opt = Adam(lr=INIT_LR, decay=INIT_LR / EPOCHS)\n",
    "model.compile(loss=\"binary_crossentropy\", optimizer=opt, metrics=[\"accuracy\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "c61079de",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "# from tensorflow.keras.utils.vis_utils import plot_model\n",
    "from tensorflow.keras.utils import plot_model\n",
    "import os\n",
    "from tensorflow.keras.optimizers import Adam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "b6755398",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('You must install pydot (`pip install pydot`) and install graphviz (see instructions at https://graphviz.gitlab.io/download/) ', 'for plot_model/model_to_dot to work.')\n"
     ]
    }
   ],
   "source": [
    "os.environ[\"PATH\"] += os.pathsep + 'C:\\\\Users\\\\1000246125\\\\AppData\\\\Local\\\\Continuum\\\\anaconda3\\\\Library\\\\bin'\n",
    "model = Sequential()\n",
    "model.add(Dense(2, input_dim=7*7*512, activation='relu'))\n",
    "model.add(Dense(4, activation='softmax'))\n",
    "plot_model(model, to_file='model_plot.png', show_shapes=True, show_layer_names=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "383be612",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/7\n",
      "73/73 [==============================] - 2s 16ms/step - loss: 0.0699 - accuracy: 0.9996 - val_loss: 2.0294e-04 - val_accuracy: 1.0000\n",
      "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "Epoch 2/7\n",
      "73/73 [==============================] - 1s 8ms/step - loss: 1.7389e-04 - accuracy: 1.0000 - val_loss: 1.4499e-04 - val_accuracy: 1.0000\n",
      "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "Epoch 3/7\n",
      "73/73 [==============================] - 1s 8ms/step - loss: 1.2951e-04 - accuracy: 1.0000 - val_loss: 1.1097e-04 - val_accuracy: 1.0000\n",
      "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "Epoch 4/7\n",
      "73/73 [==============================] - 1s 8ms/step - loss: 1.0122e-04 - accuracy: 1.0000 - val_loss: 8.8660e-05 - val_accuracy: 1.0000\n",
      "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "Epoch 5/7\n",
      "73/73 [==============================] - 1s 8ms/step - loss: 8.2213e-05 - accuracy: 1.0000 - val_loss: 7.3259e-05 - val_accuracy: 1.0000\n",
      "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "Epoch 6/7\n",
      "73/73 [==============================] - 1s 8ms/step - loss: 6.8829e-05 - accuracy: 1.0000 - val_loss: 6.2154e-05 - val_accuracy: 1.0000\n",
      "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "Epoch 7/7\n",
      "73/73 [==============================] - 1s 8ms/step - loss: 5.8997e-05 - accuracy: 1.0000 - val_loss: 5.3830e-05 - val_accuracy: 1.0000\n",
      "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n"
     ]
    }
   ],
   "source": [
    "INIT_LR = 1e-1\n",
    "EPOCHS = 30\n",
    "\n",
    "opt = Adam(lr=INIT_LR, decay=INIT_LR / EPOCHS)\n",
    "\n",
    "model.compile(loss=\"binary_crossentropy\", optimizer=opt, metrics=[\"accuracy\"])\n",
    "\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint\n",
    "\n",
    "checkpoint = ModelCheckpoint('VGG16.h5', verbose=1, monitor='val_acc', save_best_only=True, mode='auto') \n",
    "\n",
    "history = model.fit(train_features, train_labels,\n",
    "                    epochs=7,\n",
    "                    batch_size=batch_size,\n",
    "                    validation_data=(validation_features, validation_labels),\n",
    "                    callbacks=[checkpoint])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80abf899",
   "metadata": {},
   "source": [
    "# VGG16 (Frozen first 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "4d7ec090",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 4153 images belonging to 5 classes.\n",
      "Found 1779 images belonging to 5 classes.\n"
     ]
    }
   ],
   "source": [
    "datagen = ImageDataGenerator(\n",
    "    rotation_range=30, width_shift_range=0.15,\n",
    "    height_shift_range=0.15, shear_range=0.15, \n",
    "    zoom_range=0.2,horizontal_flip=True, \n",
    "    fill_mode=\"nearest\", validation_split=0.3)\n",
    "batch_size = 32\n",
    "\n",
    "train_generator = datagen.flow_from_directory(\n",
    "    r\"C:\\Users\\Home\\Desktop\\Rice Leaf Disease\",\n",
    "    target_size=(224, 224),\n",
    "    batch_size=batch_size,\n",
    "    class_mode='categorical',\n",
    "    subset='training')\n",
    "\n",
    "val_generator = datagen.flow_from_directory(\n",
    "    r\"C:\\Users\\Home\\Desktop\\Rice Leaf Disease\",\n",
    "    target_size=(224, 224),\n",
    "    batch_size=batch_size,\n",
    "    class_mode='categorical',\n",
    "    subset='validation')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "010ac9ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "conv_base.trainable = True\n",
    "\n",
    "set_trainable = False\n",
    "for layer in conv_base.layers:\n",
    "    if layer.name == 'block4_conv1':\n",
    "        set_trainable = True\n",
    "    if set_trainable:\n",
    "        layer.trainable = True\n",
    "    else:\n",
    "        layer.trainable = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "3fd161af",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = models.Sequential()\n",
    "model.add(conv_base)\n",
    "model.add(layers.Flatten())\n",
    "model.add(layers.Dense(256, activation='relu', input_dim=7 * 7 * 512))\n",
    "# model.add(layers.Dropout(0.2))\n",
    "model.add(layers.Dense(128, activation='relu'))\n",
    "# model.add(layers.Dropout(0.2))  #Removing 50% of the weights!\n",
    "model.add(layers.Dense(5, activation='softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cdb61e71",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.optimizers import Adam\n",
    "\n",
    "INIT_LR = 1e-3\n",
    "EPOCHS = 30\n",
    "\n",
    "opt = Adam(lr=INIT_LR, decay=INIT_LR / EPOCHS)\n",
    "\n",
    "model.compile(loss=\"binary_crossentropy\", optimizer=opt, metrics=[\"accuracy\"])\n",
    "\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint\n",
    "\n",
    "checkpoint = ModelCheckpoint('VGG16_frozen3.h5', verbose=1, monitor='val_acc', save_best_only=True, mode='auto') \n",
    "\n",
    "history = model.fit_generator(train_generator,\n",
    "                    epochs=2,\n",
    "                    steps_per_epoch=7*7*512 / batch_size,\n",
    "                    validation_data=val_generator,\n",
    "                    callbacks=[checkpoint])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
